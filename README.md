# ai-safety
Learning in public. A collection of reading materials and personal exploration on AI safety.

## Resources
Neel Nanda's [Concrete Steps to Get Started in Transformer Mechanistic Interpretability](https://www.neelnanda.io/mechanistic-interpretability/getting-started). He also has an [updated draft](https://docs.google.com/document/d/11X9tEX-jxf5S9IMgG5OEXkPCnpFynff_CItTEX46T4A/edit?tab=t.0) of the post.

## Library
[The Precipice: Existential Risk and the Future of Humanity](https://www.goodreads.com/book/show/57514023-the-precipice)

## Ideas Backlog
- bluedot-intro-to-transformative-ai
  - Write blog about insights and perspectives from the resources, and discussion of each session
- two-books
  - Write blog comparing two books in a subject area
  - Motivations for reading them
  - Each book's position and context about authors and general community discussion around each one (critiques, ideas that have held on, reactions and what has happend as a result)
  - Key points
  - Key examples
  - Personal takeaways and connections I made between these books, and other things I've read
  - Connections, open discussion questions and things I'd love to hear about if I was to run a reading group on this
- two-papers
  - Same outline as two-books
  - Highlighting two ideas (different applications, or temporally different with one inspiring the other, or two seminal ideas that came together to inspire something hugely relevant today)
  - Create collection of papers and their relationships with one another as a Notion table that folks can suggest relationships between and star popular relationships they'd like to see compared (use this database of potential connections to triangulate which are promising connections to explore)
- spark-databricks
  - Tutorial on Spark and Databricks technologies (relevant for building fast machine learning pipelines)
  - How fast is fast (compared to alternatives) in terms of development simplicity and performance?
  - What is it used for/who was it designed for, who designed it, and why did they design it?
  - How does it work (architecture, common depoyments, self-hosting)
- paper-replications
  - Paper replication process advice from EA Forum [1](https://forum.effectivealtruism.org/posts/7WXPkpqKGKewAymJf/how-to-pursue-a-career-in-technical-ai-alignment#How_to_pursue_research_contributor__ML_engineering__roles), which links to [2](https://forum.effectivealtruism.org/posts/fRjj6nm9xbW4kFcTZ/advice-on-pursuing-technical-ai-safety-research#2_1__Advice_on_paper_replication).
  - 1 encourages writing for funding to do paper replications
- arena-notes
  - Useful things to include are summaries, comments, takes, disagreements, opinions, additional resources. 
- technical-reports
  - See (ARC ELK technical report)[https://www.lesswrong.com/posts/QEYWkRoCn4fZxXQAY/prizes-for-elk-proposals] for inspiration.
  - A reasonable estimate of time is spendig 50 hours learning, and 50 hours producing in a way that covers enough breadth to talk about the main areas sensibly, know about recent advances, and having depth in the area proposed exploration is in.
